{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"Images/PU.png\" width=\"100%\">\n",
    "\n",
    "## Course Name : AI 702 Deep Learning for Professionals  \n",
    "#### Notebook compiled by : Bhushan Garware, Project Lead at Learning and Development  \n",
    "** Important ! ** For internal circulation olny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "#keras would download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_words = 5000  # working only on 5000 unique words \n",
    "n_words_to_skip = 50   # we are skipping top 50 words such as: an, is, the, of and so on \n",
    "#change above to something like below and see what is does..\n",
    "#It starts looking at words like \"this\" \"film\" \"was\" \"just\" which will be every where\n",
    "#n_unique_words = 50000\n",
    "#n_words_to_skip = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset created by Stanford University Students and is part of the keras library now. When your notebook contains code to load the data it gets stored on your local disk under ./keras. Under keras folder you would find model folder where all pretrained models are saved. Data that you load goes under Datasets folder (imdb.npz)\n",
    "\n",
    "Check C:\\Users\\rajiv_kale\\.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words, skip_top=n_words_to_skip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 2,\n",
       " 173,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 100,\n",
       " 2,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 284,\n",
       " 2,\n",
       " 150,\n",
       " 2,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 2,\n",
       " 2,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 2,\n",
       " 546,\n",
       " 2,\n",
       " 2,\n",
       " 447,\n",
       " 2,\n",
       " 192,\n",
       " 50,\n",
       " 2,\n",
       " 2,\n",
       " 147,\n",
       " 2025,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 2,\n",
       " 2,\n",
       " 71,\n",
       " 87,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 2,\n",
       " 76,\n",
       " 2,\n",
       " 2,\n",
       " 1247,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 515,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 626,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 62,\n",
       " 386,\n",
       " 2,\n",
       " 2,\n",
       " 316,\n",
       " 2,\n",
       " 106,\n",
       " 2,\n",
       " 2,\n",
       " 2223,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 2,\n",
       " 2,\n",
       " 130,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 619,\n",
       " 2,\n",
       " 2,\n",
       " 124,\n",
       " 51,\n",
       " 2,\n",
       " 135,\n",
       " 2,\n",
       " 2,\n",
       " 1415,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 215,\n",
       " 2,\n",
       " 77,\n",
       " 52,\n",
       " 2,\n",
       " 2,\n",
       " 407,\n",
       " 2,\n",
       " 82,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 107,\n",
       " 117,\n",
       " 2,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3766,\n",
       " 2,\n",
       " 723,\n",
       " 2,\n",
       " 71,\n",
       " 2,\n",
       " 530,\n",
       " 476,\n",
       " 2,\n",
       " 400,\n",
       " 317,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1029,\n",
       " 2,\n",
       " 104,\n",
       " 88,\n",
       " 2,\n",
       " 381,\n",
       " 2,\n",
       " 297,\n",
       " 98,\n",
       " 2,\n",
       " 2071,\n",
       " 56,\n",
       " 2,\n",
       " 141,\n",
       " 2,\n",
       " 194,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 226,\n",
       " 2,\n",
       " 2,\n",
       " 134,\n",
       " 476,\n",
       " 2,\n",
       " 480,\n",
       " 2,\n",
       " 144,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 51,\n",
       " 2,\n",
       " 2,\n",
       " 224,\n",
       " 92,\n",
       " 2,\n",
       " 104,\n",
       " 2,\n",
       " 226,\n",
       " 65,\n",
       " 2,\n",
       " 2,\n",
       " 1334,\n",
       " 88,\n",
       " 2,\n",
       " 2,\n",
       " 283,\n",
       " 2,\n",
       " 2,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 178,\n",
       " 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above first training example (movie review that somebody has typed) is stored in the form of numbers based on popularity of that word.  Popularity index is first created for top 5000 words leaving the rest. Now, during conversion to numeric form, start reading the document, take the word and check its rank in popularity index and replace that word with popularity number. 2 is reserved for unknown words (those words beyond 5000 which we have not considered). If word is most popular its number would be 3. Next most popular would be 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train[0] has this text\n",
    "UNK UNK UNK UNK UNK brilliant casting location...\n",
    "brilliant is at 528 (530-2) in popularity ranking and casting is at 971"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 reserved for padding\n",
    "### 1 would be starting character\n",
    "### 2 is unknown \n",
    "### 3 is most common word\n",
    "### 4 is second most comman word and so on...\n",
    "### 530 is the 528th most comman word from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2]),\n",
       "       list([2, 194, 1153, 194, 2, 78, 228, 2, 2, 1463, 4369, 2, 134, 2, 2, 715, 2, 118, 1634, 2, 394, 2, 2, 119, 954, 189, 102, 2, 207, 110, 3103, 2, 2, 69, 188, 2, 2, 2, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 2, 2, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 2, 2, 1002, 2, 89, 2, 952, 2, 2, 2, 455, 2, 2, 2, 2, 1543, 1905, 398, 2, 1649, 2, 2, 2, 163, 2, 3215, 2, 2, 1153, 2, 194, 775, 2, 2, 2, 349, 2637, 148, 605, 2, 2, 2, 123, 125, 68, 2, 2, 2, 349, 165, 4362, 98, 2, 2, 228, 2, 2, 2, 1157, 2, 299, 120, 2, 120, 174, 2, 220, 175, 136, 50, 2, 4373, 228, 2, 2, 2, 656, 245, 2350, 2, 2, 2, 131, 152, 491, 2, 2, 2, 2, 1212, 2, 2, 2, 371, 78, 2, 625, 64, 1382, 2, 2, 168, 145, 2, 2, 1690, 2, 2, 2, 1355, 2, 2, 2, 52, 154, 462, 2, 89, 78, 285, 2, 145, 95]),\n",
       "       list([2, 2, 2, 2, 2, 2, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 2, 71, 149, 2, 2, 112, 2, 2401, 311, 2, 2, 3711, 2, 75, 2, 1829, 296, 2, 86, 320, 2, 534, 2, 263, 4821, 1301, 2, 1873, 2, 89, 78, 2, 66, 2, 2, 360, 2, 2, 58, 316, 334, 2, 2, 1716, 2, 645, 662, 2, 257, 85, 1200, 2, 1228, 2578, 83, 68, 3912, 2, 2, 165, 1539, 278, 2, 69, 2, 780, 2, 106, 2, 2, 1338, 2, 2, 2, 2, 215, 2, 610, 2, 2, 87, 326, 2, 2300, 2, 2, 2, 2, 272, 2, 57, 2, 2, 2, 2, 2, 2, 2307, 51, 2, 170, 2, 595, 116, 595, 1352, 2, 191, 79, 638, 89, 2, 2, 2, 2, 106, 607, 624, 2, 534, 2, 227, 2, 129, 113]),\n",
       "       list([2, 2, 2, 2, 2, 2804, 2, 2040, 432, 111, 153, 103, 2, 1494, 2, 70, 131, 67, 2, 61, 2, 744, 2, 3715, 761, 61, 2, 452, 2, 2, 985, 2, 2, 59, 166, 2, 105, 216, 1239, 2, 1797, 2, 2, 2, 2, 744, 2413, 2, 2, 2, 687, 2, 2, 2, 2, 2, 3693, 2, 2, 2, 121, 59, 456, 2, 2, 2, 265, 2, 575, 111, 153, 159, 59, 2, 1447, 2, 2, 586, 482, 2, 2, 96, 59, 716, 2, 2, 172, 65, 2, 579, 2, 2, 2, 1615, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 464, 2, 314, 2, 2, 2, 719, 605, 2, 2, 202, 2, 310, 2, 3772, 3501, 2, 2722, 58, 2, 2, 537, 2116, 180, 2, 2, 413, 173, 2, 263, 112, 2, 152, 377, 2, 537, 263, 846, 579, 178, 54, 75, 71, 476, 2, 413, 263, 2504, 182, 2, 2, 75, 2306, 922, 2, 279, 131, 2895, 2, 2867, 2, 2, 2, 921, 2, 192, 2, 1219, 3890, 2, 2, 217, 4122, 1710, 537, 2, 1236, 2, 736, 2, 2, 61, 403, 2, 2, 2, 61, 4494, 2, 2, 4494, 159, 90, 263, 2311, 4319, 309, 2, 178, 2, 82, 4319, 2, 65, 2, 2, 145, 143, 2, 2, 2, 537, 746, 537, 537, 2, 2, 2, 2, 594, 2, 2, 94, 2, 3987, 2, 2, 2, 2, 538, 2, 1795, 246, 2, 2, 2, 2, 635, 2, 2, 51, 408, 2, 94, 318, 1382, 2, 2, 2, 2683, 936, 2, 2, 2, 2, 2, 2, 2, 1885, 2, 1118, 2, 80, 126, 842, 2, 2, 2, 2, 4726, 2, 4494, 2, 1550, 3633, 159, 2, 341, 2, 2733, 2, 4185, 173, 2, 90, 2, 2, 2, 2, 2, 1784, 86, 1117, 2, 3261, 2, 2, 2, 2, 2, 2, 2841, 2, 2, 1010, 2, 793, 2, 2, 1386, 1830, 2, 2, 246, 50, 2, 2, 2750, 1944, 746, 90, 2, 2, 2, 124, 2, 882, 2, 882, 496, 2, 2, 2213, 537, 121, 127, 1219, 130, 2, 2, 494, 2, 124, 2, 882, 496, 2, 341, 2, 2, 846, 2, 2, 2, 2, 1906, 2, 97, 2, 236, 2, 1311, 2, 2, 2, 2, 2, 2, 2, 91, 2, 3987, 70, 2, 882, 2, 579, 2, 2, 2, 2, 2, 537, 2, 2, 2, 2, 65, 2, 537, 75, 2, 1775, 3353, 2, 1846, 2, 2, 2, 154, 2, 2, 518, 53, 2, 2, 2, 3211, 882, 2, 399, 2, 75, 257, 3807, 2, 2, 2, 2, 456, 2, 65, 2, 2, 205, 113, 2, 2, 2, 2, 2, 2, 2, 242, 2, 91, 1202, 2, 2, 2070, 307, 2, 2, 2, 126, 93, 2, 2, 2, 188, 1076, 3222, 2, 2, 2, 2, 2348, 537, 2, 53, 537, 2, 82, 2, 2, 2, 2, 2, 280, 2, 219, 2, 2, 431, 758, 859, 2, 953, 1052, 2, 2, 2, 2, 94, 2, 2, 238, 60, 2, 2, 2, 804, 2, 2, 2, 2, 132, 2, 67, 2, 2, 2, 2, 283, 2, 2, 2, 2, 2, 242, 955, 2, 2, 279, 2, 2, 2, 1685, 195, 2, 238, 60, 796, 2, 2, 671, 2, 2804, 2, 2, 559, 154, 888, 2, 726, 50, 2, 2, 2, 2, 566, 2, 579, 2, 64, 2574]),\n",
       "       list([2, 249, 1323, 2, 61, 113, 2, 2, 2, 1637, 2, 2, 56, 2, 2401, 2, 457, 88, 2, 2626, 1400, 2, 3171, 2, 70, 79, 2, 706, 919, 2, 2, 355, 340, 355, 1696, 96, 143, 2, 2, 2, 289, 2, 61, 369, 71, 2359, 2, 2, 2, 131, 2073, 249, 114, 249, 229, 249, 2, 2, 2, 126, 110, 2, 473, 2, 569, 61, 419, 56, 429, 2, 1513, 2, 2, 534, 95, 474, 570, 2, 2, 124, 138, 88, 2, 421, 1543, 52, 725, 2, 61, 419, 2, 2, 1571, 2, 1543, 2, 2, 2, 2, 2, 296, 2, 3524, 2, 2, 421, 128, 74, 233, 334, 207, 126, 224, 2, 562, 298, 2167, 1272, 2, 2601, 2, 516, 988, 2, 2, 79, 120, 2, 595, 2, 784, 2, 3171, 2, 165, 170, 143, 2, 2, 2, 2, 2, 226, 251, 2, 61, 113]),\n",
       "       list([2, 778, 128, 74, 2, 630, 163, 2, 2, 1766, 2, 1051, 2, 2, 85, 156, 2, 2, 148, 139, 121, 664, 665, 2, 2, 1361, 173, 2, 749, 2, 2, 3804, 2, 2, 226, 65, 2, 2, 127, 2, 2, 2, 2])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n",
      "141\n",
      "550\n",
      "147\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "for x in x_train[0:6]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring words from the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"PAD\"] = 0\n",
    "word_index[\"START\"] = 1\n",
    "word_index[\"UNK\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"this\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 2,\n",
       " 173,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 100,\n",
       " 2,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 284,\n",
       " 2,\n",
       " 150,\n",
       " 2,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 2,\n",
       " 2,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 2,\n",
       " 546,\n",
       " 2,\n",
       " 2,\n",
       " 447,\n",
       " 2,\n",
       " 192,\n",
       " 50,\n",
       " 2,\n",
       " 2,\n",
       " 147,\n",
       " 2025,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 2,\n",
       " 2,\n",
       " 71,\n",
       " 87,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 2,\n",
       " 76,\n",
       " 2,\n",
       " 2,\n",
       " 1247,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 515,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 626,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 62,\n",
       " 386,\n",
       " 2,\n",
       " 2,\n",
       " 316,\n",
       " 2,\n",
       " 106,\n",
       " 2,\n",
       " 2,\n",
       " 2223,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 2,\n",
       " 2,\n",
       " 130,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 619,\n",
       " 2,\n",
       " 2,\n",
       " 124,\n",
       " 51,\n",
       " 2,\n",
       " 135,\n",
       " 2,\n",
       " 2,\n",
       " 1415,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 215,\n",
       " 2,\n",
       " 77,\n",
       " 52,\n",
       " 2,\n",
       " 2,\n",
       " 407,\n",
       " 2,\n",
       " 82,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 107,\n",
       " 117,\n",
       " 2,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3766,\n",
       " 2,\n",
       " 723,\n",
       " 2,\n",
       " 71,\n",
       " 2,\n",
       " 530,\n",
       " 476,\n",
       " 2,\n",
       " 400,\n",
       " 317,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1029,\n",
       " 2,\n",
       " 104,\n",
       " 88,\n",
       " 2,\n",
       " 381,\n",
       " 2,\n",
       " 297,\n",
       " 98,\n",
       " 2,\n",
       " 2071,\n",
       " 56,\n",
       " 2,\n",
       " 141,\n",
       " 2,\n",
       " 194,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 226,\n",
       " 2,\n",
       " 2,\n",
       " 134,\n",
       " 476,\n",
       " 2,\n",
       " 480,\n",
       " 2,\n",
       " 144,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 51,\n",
       " 2,\n",
       " 2,\n",
       " 224,\n",
       " 92,\n",
       " 2,\n",
       " 104,\n",
       " 2,\n",
       " 226,\n",
       " 65,\n",
       " 2,\n",
       " 2,\n",
       " 1334,\n",
       " 88,\n",
       " 2,\n",
       " 2,\n",
       " 283,\n",
       " 2,\n",
       " 2,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 178,\n",
       " 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UNK UNK UNK UNK UNK brilliant casting location scenery story direction everyone's really suited UNK part UNK played UNK UNK could UNK imagine being there robert UNK UNK UNK amazing actor UNK now UNK same being director UNK father came UNK UNK same scottish island UNK myself UNK UNK loved UNK fact there UNK UNK real connection UNK UNK UNK UNK witty remarks throughout UNK UNK were great UNK UNK UNK brilliant UNK much UNK UNK bought UNK UNK UNK soon UNK UNK UNK released UNK UNK UNK would recommend UNK UNK everyone UNK watch UNK UNK fly UNK UNK amazing really cried UNK UNK end UNK UNK UNK sad UNK UNK know what UNK say UNK UNK cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in x_train[0])\n",
    "#brillinat comes as part of top 5000 words in the corpus and is not part of top 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_x_train,_),(all_x_valid,_) = imdb.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,    2,    2,    2,    2,  215,    2,   77,   52,    2,    2,\n",
       "         407,    2,   82,    2,    2,    2,  107,  117,    2,    2,  256,\n",
       "           2,    2,    2, 3766,    2,  723,    2,   71,    2,  530,  476,\n",
       "           2,  400,  317,    2,    2,    2,    2, 1029,    2,  104,   88,\n",
       "           2,  381,    2,  297,   98,    2, 2071,   56,    2,  141,    2,\n",
       "         194,    2,    2,    2,  226,    2,    2,  134,  476,    2,  480,\n",
       "           2,  144,    2,    2,    2,   51,    2,    2,  224,   92,    2,\n",
       "         104,    2,  226,   65,    2,    2, 1334,   88,    2,    2,  283,\n",
       "           2,    2, 4472,  113,  103,    2,    2,    2,    2,    2,  178,\n",
       "           2],\n",
       "       [ 163,    2, 3215,    2,    2, 1153,    2,  194,  775,    2,    2,\n",
       "           2,  349, 2637,  148,  605,    2,    2,    2,  123,  125,   68,\n",
       "           2,    2,    2,  349,  165, 4362,   98,    2,    2,  228,    2,\n",
       "           2,    2, 1157,    2,  299,  120,    2,  120,  174,    2,  220,\n",
       "         175,  136,   50,    2, 4373,  228,    2,    2,    2,  656,  245,\n",
       "        2350,    2,    2,    2,  131,  152,  491,    2,    2,    2,    2,\n",
       "        1212,    2,    2,    2,  371,   78,    2,  625,   64, 1382,    2,\n",
       "           2,  168,  145,    2,    2, 1690,    2,    2,    2, 1355,    2,\n",
       "           2,    2,   52,  154,  462,    2,   89,   78,  285,    2,  145,\n",
       "          95],\n",
       "       [1301,    2, 1873,    2,   89,   78,    2,   66,    2,    2,  360,\n",
       "           2,    2,   58,  316,  334,    2,    2, 1716,    2,  645,  662,\n",
       "           2,  257,   85, 1200,    2, 1228, 2578,   83,   68, 3912,    2,\n",
       "           2,  165, 1539,  278,    2,   69,    2,  780,    2,  106,    2,\n",
       "           2, 1338,    2,    2,    2,    2,  215,    2,  610,    2,    2,\n",
       "          87,  326,    2, 2300,    2,    2,    2,    2,  272,    2,   57,\n",
       "           2,    2,    2,    2,    2,    2, 2307,   51,    2,  170,    2,\n",
       "         595,  116,  595, 1352,    2,  191,   79,  638,   89,    2,    2,\n",
       "           2,    2,  106,  607,  624,    2,  534,    2,  227,    2,  129,\n",
       "         113],\n",
       "       [   2,    2,    2,  188, 1076, 3222,    2,    2,    2,    2, 2348,\n",
       "         537,    2,   53,  537,    2,   82,    2,    2,    2,    2,    2,\n",
       "         280,    2,  219,    2,    2,  431,  758,  859,    2,  953, 1052,\n",
       "           2,    2,    2,    2,   94,    2,    2,  238,   60,    2,    2,\n",
       "           2,  804,    2,    2,    2,    2,  132,    2,   67,    2,    2,\n",
       "           2,    2,  283,    2,    2,    2,    2,    2,  242,  955,    2,\n",
       "           2,  279,    2,    2,    2, 1685,  195,    2,  238,   60,  796,\n",
       "           2,    2,  671,    2, 2804,    2,    2,  559,  154,  888,    2,\n",
       "         726,   50,    2,    2,    2,    2,  566,    2,  579,    2,   64,\n",
       "        2574],\n",
       "       [   2,    2,  131, 2073,  249,  114,  249,  229,  249,    2,    2,\n",
       "           2,  126,  110,    2,  473,    2,  569,   61,  419,   56,  429,\n",
       "           2, 1513,    2,    2,  534,   95,  474,  570,    2,    2,  124,\n",
       "         138,   88,    2,  421, 1543,   52,  725,    2,   61,  419,    2,\n",
       "           2, 1571,    2, 1543,    2,    2,    2,    2,    2,  296,    2,\n",
       "        3524,    2,    2,  421,  128,   74,  233,  334,  207,  126,  224,\n",
       "           2,  562,  298, 2167, 1272,    2, 2601,    2,  516,  988,    2,\n",
       "           2,   79,  120,    2,  595,    2,  784,    2, 3171,    2,  165,\n",
       "         170,  143,    2,    2,    2,    2,    2,  226,  251,    2,   61,\n",
       "         113],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2,  778,  128,   74,    2,  630,  163,    2,    2,\n",
       "        1766,    2, 1051,    2,    2,   85,  156,    2,    2,  148,  139,\n",
       "         121,  664,  665,    2,    2, 1361,  173,    2,  749,    2,    2,\n",
       "        3804,    2,    2,  226,   65,    2,    2,  127,    2,    2,    2,\n",
       "           2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for x in x_train[0:6]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD UNK begins better than UNK ends funny UNK UNK russian UNK crew UNK UNK other actors UNK UNK those scenes where documentary shots UNK UNK spoiler part UNK message UNK UNK contrary UNK UNK whole story UNK UNK does UNK UNK UNK UNK'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_unique_words = 7\\nn_dim = 2\\ndense_dim = 4\\nmax_review_length = 5\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# vector-space embedding: \n",
    "#n_unique_words = 5000\n",
    "#max_review_length = 100\n",
    "\n",
    "n_unique_words = 5000\n",
    "n_dim = 256\n",
    "dense_dim = 16\n",
    "max_review_length = 100\n",
    "'''\n",
    "n_unique_words = 7\n",
    "n_dim = 2\n",
    "dense_dim = 4\n",
    "max_review_length = 5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_unique_words is total vocabulary, n_dim is the size of 2D vector space in which words will be embedded\n",
    "# trainable parameters for Embedding Layer = n_unique_words*n_dim\n",
    "# trainable parameters for dense layer (max_review_length*n_dim*dense_dim) + dense_dim  256*100*16 + 16 = 409664\n",
    "# single neuron in the output to give us class of movie review\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_dim, activation='relu'))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 256)          1280000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                409616    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,689,633\n",
      "Trainable params: 1,689,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 24s 950us/step - loss: 0.5779 - acc: 0.6612 - val_loss: 0.3795 - val_acc: 0.8416\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 24s 969us/step - loss: 0.3287 - acc: 0.8474 - val_loss: 0.3409 - val_acc: 0.8500\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 23s 929us/step - loss: 0.1310 - acc: 0.9570 - val_loss: 0.4231 - val_acc: 0.8363\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 24s 962us/step - loss: 0.0231 - acc: 0.9952 - val_loss: 0.5555 - val_acc: 0.8355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b7309cc6d8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.467811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.922040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.998329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.992276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.996844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_hat  y\n",
       "0  0.037913  0\n",
       "1  0.999296  1\n",
       "2  0.868223  1\n",
       "3  0.467811  0\n",
       "4  0.999996  1\n",
       "5  0.922040  1\n",
       "6  0.998329  1\n",
       "7  0.000538  0\n",
       "8  0.992276  0\n",
       "9  0.996844  1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted and actual to get general idea on model performance\n",
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])\n",
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.992276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.917169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.998646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.999290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.937748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.986756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.958135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.986040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.999652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.996680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_hat  y\n",
       "8    0.992276  0\n",
       "17   0.917169  0\n",
       "66   0.998646  0\n",
       "75   0.999290  0\n",
       "95   0.937748  0\n",
       "112  0.986756  0\n",
       "115  0.958135  0\n",
       "139  0.986040  0\n",
       "152  0.999652  0\n",
       "156  0.996680  0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print wrong predictions\n",
    "ydf[(ydf.y == 0) & (ydf.y_hat > 0.9)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1411, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf[(ydf.y == 0) & (ydf.y_hat > 0.9)].shape    # checking how many wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START apparently the film has a harsh anti bush message if it does i didn't get it that's all it is it's boring and useless period br br it's too serious at times to be a comedy too slow to be a thriller not funny not gripping not exciting not film it's too everything to be the opposite and vise versa i was amazed at how bad a film could suck don't even think of watching it br br i have watched literally hundreds of films and never have i been so obliged to write a warning on imdb avoid at all costs you have been warned br br even the making of is painfully boring it's just people talking gibberish with loads of inside jokes infront of a camera sort of like a home movie there even is a part where a guy takes you on a tour of the food that was consumed on the set by the film crew still beats the movie i guess\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[489]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Crude way for converting Text into vectors where semantics of the narrative is lost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us also see how 1D Convolution can be applied to do feature extraction on top of Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
